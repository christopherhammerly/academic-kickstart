percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
#group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
#group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
group_by(Experiment, region) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
group_by(Experiment, region) %>%
filter(RT < 100 | RT > 6000)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)
#   A function that gets around the issue of turning factors numeric
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
# Load data
data.all <- read.csv('~/Desktop/Current-Projects/Resumption-LI/data-all.csv',
header = T,
sep = ",",
#col.names=mycols,
fill = TRUE)
# Load question answer key
answers <- read.delim('~/Desktop/Current-Projects/Resumption-LI/answers.txt',
header = 1,
sep = "\t")
answers$Item <- as.factor(as.character(answers$Item))
# Create data frame for comprehension questions, only experimental items
data.comprehension <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "Question"))
data.comprehension$RT <- as.numeric(as.character(data.comprehension$RT))
# Create data frame for fillers
fillers.comprehension <- droplevels(subset(data.all, Experiment %in% c("filler") & TrialType == "Question"))
# Filler accuracy analysis
filler.accuracy <- fillers.comprehension %>%
group_by(Subject) %>%
summarise(Accuracy = mean(Accuracy))
filler.mean <- mean(filler.accuracy$Accuracy)
filler.SD <- sd(filler.accuracy$Accuracy)
filler.cutoff <- filler.mean - (2*filler.SD)
# Create data frame with experimental RT data
data.spr <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "DashedSentence"))
names(data.spr) <- c("Subject","MD5","TrialType","Number","Element","Experiment","Item", "region", "fragment","RT","NULL", "Sentence","Dependency","Islandhood")
data.spr <- data.spr %>%
mutate(length = nchar(as.character(fragment))) %>%
mutate("LengthRT" = RT/length)
# Add columns for verb-type. Not used here, but could be used for post-hoc analysis
announce <- c(1:4)
found <- c(5:12)
discover <- c(13:16)
learn <- c(17:20)
realize <- c(21:24)
data.comprehension$Verb <- ifelse(data.comprehension$Item %in% announce, "accounced",
ifelse(data.comprehension$Item %in% found, "found out",
ifelse(data.comprehension$Item %in% discover, "discovered",
ifelse(data.comprehension$Item %in% learn, "learned","realized"))))
data.spr$Verb <- ifelse(data.spr$Item %in% announce, "accounced",
ifelse(data.spr$Item %in% found, "found out",
ifelse(data.spr$Item %in% discover, "discovered",
ifelse(data.spr$Item %in% learn, "learned","realized"))))
#   Exclude trials where a chunk is read slower than 6000ms above the average and faster than 100ms
SPR.mean <- mean(data.spr$RT)
SPR.SD <- sd(data.spr$RT)
high.cutoff <- SPR.mean + (2.5*SPR.SD)
low.cutoff <- SPR.mean - (2.5*SPR.SD)
# Absolute RT cutoff
bad.trials <- data.spr %>%
group_by(Experiment, region) %>%
filter(RT < 100 | RT > 6000)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
data.comprehension <- droplevels((subset(data.comprehension, !(ID %in% bad.trials$ID))))
data.spr <- droplevels((subset(data.spr, !(ID %in% bad.trials$ID))))
# Double check number of subjects
print(data.comprehension %>% summarise(number = n_distinct(Subject)))
print(data.spr %>% summarise(number = n_distinct(Subject)))
#   A function that gets around the issue of turning factors numeric
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
# Load data
data.all <- read.csv('~/Desktop/Current-Projects/Resumption-LI/data-all.csv',
header = T,
sep = ",",
#col.names=mycols,
fill = TRUE)
# Load question answer key
answers <- read.delim('~/Desktop/Current-Projects/Resumption-LI/answers.txt',
header = 1,
sep = "\t")
answers$Item <- as.factor(as.character(answers$Item))
# Create data frame for comprehension questions, only experimental items
data.comprehension <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "Question"))
data.comprehension$RT <- as.numeric(as.character(data.comprehension$RT))
# Create data frame for fillers
fillers.comprehension <- droplevels(subset(data.all, Experiment %in% c("filler") & TrialType == "Question"))
# Filler accuracy analysis
filler.accuracy <- fillers.comprehension %>%
group_by(Subject) %>%
summarise(Accuracy = mean(Accuracy))
filler.mean <- mean(filler.accuracy$Accuracy)
filler.SD <- sd(filler.accuracy$Accuracy)
filler.cutoff <- filler.mean - (2*filler.SD)
# Create data frame with experimental RT data
data.spr <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "DashedSentence"))
names(data.spr) <- c("Subject","MD5","TrialType","Number","Element","Experiment","Item", "region", "fragment","RT","NULL", "Sentence","Dependency","Islandhood")
data.spr <- data.spr %>%
mutate(length = nchar(as.character(fragment))) %>%
mutate("LengthRT" = RT/length)
# Add columns for verb-type. Not used here, but could be used for post-hoc analysis
announce <- c(1:4)
found <- c(5:12)
discover <- c(13:16)
learn <- c(17:20)
realize <- c(21:24)
data.comprehension$Verb <- ifelse(data.comprehension$Item %in% announce, "accounced",
ifelse(data.comprehension$Item %in% found, "found out",
ifelse(data.comprehension$Item %in% discover, "discovered",
ifelse(data.comprehension$Item %in% learn, "learned","realized"))))
data.spr$Verb <- ifelse(data.spr$Item %in% announce, "accounced",
ifelse(data.spr$Item %in% found, "found out",
ifelse(data.spr$Item %in% discover, "discovered",
ifelse(data.spr$Item %in% learn, "learned","realized"))))
#   Exclude trials where a chunk is read slower than 6000ms above the average and faster than 100ms
SPR.mean <- mean(data.spr$RT)
SPR.SD <- sd(data.spr$RT)
high.cutoff <- SPR.mean + (2.5*SPR.SD)
low.cutoff <- SPR.mean - (2.5*SPR.SD)
bad.trials <- data.spr %>%
#group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
#group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
group_by(Subject) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
group_by(Subject, region) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
bad.trials <- data.spr %>%
group_by(Item, region) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)
#   A function that gets around the issue of turning factors numeric
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
# Load data
data.all <- read.csv('~/Desktop/Current-Projects/Resumption-LI/data-all.csv',
header = T,
sep = ",",
#col.names=mycols,
fill = TRUE)
# Load question answer key
answers <- read.delim('~/Desktop/Current-Projects/Resumption-LI/answers.txt',
header = 1,
sep = "\t")
answers$Item <- as.factor(as.character(answers$Item))
# Create data frame for comprehension questions, only experimental items
data.comprehension <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "Question"))
data.comprehension$RT <- as.numeric(as.character(data.comprehension$RT))
# Create data frame for fillers
fillers.comprehension <- droplevels(subset(data.all, Experiment %in% c("filler") & TrialType == "Question"))
# Filler accuracy analysis
filler.accuracy <- fillers.comprehension %>%
group_by(Subject) %>%
summarise(Accuracy = mean(Accuracy))
filler.mean <- mean(filler.accuracy$Accuracy)
filler.SD <- sd(filler.accuracy$Accuracy)
filler.cutoff <- filler.mean - (2*filler.SD)
# Create data frame with experimental RT data
data.spr <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "DashedSentence"))
names(data.spr) <- c("Subject","MD5","TrialType","Number","Element","Experiment","Item", "region", "fragment","RT","NULL", "Sentence","Dependency","Islandhood")
data.spr <- data.spr %>%
mutate(length = nchar(as.character(fragment))) %>%
mutate("LengthRT" = RT/length)
# Add columns for verb-type. Not used here, but could be used for post-hoc analysis
announce <- c(1:4)
found <- c(5:12)
discover <- c(13:16)
learn <- c(17:20)
realize <- c(21:24)
data.comprehension$Verb <- ifelse(data.comprehension$Item %in% announce, "accounced",
ifelse(data.comprehension$Item %in% found, "found out",
ifelse(data.comprehension$Item %in% discover, "discovered",
ifelse(data.comprehension$Item %in% learn, "learned","realized"))))
data.spr$Verb <- ifelse(data.spr$Item %in% announce, "accounced",
ifelse(data.spr$Item %in% found, "found out",
ifelse(data.spr$Item %in% discover, "discovered",
ifelse(data.spr$Item %in% learn, "learned","realized"))))
bad.trials <- data.spr %>%
group_by(Item, region) %>%
mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)
#   A function that gets around the issue of turning factors numeric
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
# Load data
data.all <- read.csv('~/Desktop/Current-Projects/Resumption-LI/data-all.csv',
header = T,
sep = ",",
#col.names=mycols,
fill = TRUE)
# Load question answer key
answers <- read.delim('~/Desktop/Current-Projects/Resumption-LI/answers.txt',
header = 1,
sep = "\t")
answers$Item <- as.factor(as.character(answers$Item))
# Create data frame for comprehension questions, only experimental items
data.comprehension <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "Question"))
data.comprehension$RT <- as.numeric(as.character(data.comprehension$RT))
# Create data frame for fillers
fillers.comprehension <- droplevels(subset(data.all, Experiment %in% c("filler") & TrialType == "Question"))
# Filler accuracy analysis
filler.accuracy <- fillers.comprehension %>%
group_by(Subject) %>%
summarise(Accuracy = mean(Accuracy))
filler.mean <- mean(filler.accuracy$Accuracy)
filler.SD <- sd(filler.accuracy$Accuracy)
filler.cutoff <- filler.mean - (2*filler.SD)
# Create data frame with experimental RT data
data.spr <- droplevels(subset(data.all, Experiment %in% c("cond-A","cond-B","cond-C","cond-D") & TrialType == "DashedSentence"))
names(data.spr) <- c("Subject","MD5","TrialType","Number","Element","Experiment","Item", "region", "fragment","RT","NULL", "Sentence","Dependency","Islandhood")
data.spr <- data.spr %>%
mutate(length = nchar(as.character(fragment))) %>%
mutate("LengthRT" = RT/length)
# Add columns for verb-type. Not used here, but could be used for post-hoc analysis
announce <- c(1:4)
found <- c(5:12)
discover <- c(13:16)
learn <- c(17:20)
realize <- c(21:24)
data.comprehension$Verb <- ifelse(data.comprehension$Item %in% announce, "accounced",
ifelse(data.comprehension$Item %in% found, "found out",
ifelse(data.comprehension$Item %in% discover, "discovered",
ifelse(data.comprehension$Item %in% learn, "learned","realized"))))
data.spr$Verb <- ifelse(data.spr$Item %in% announce, "accounced",
ifelse(data.spr$Item %in% found, "found out",
ifelse(data.spr$Item %in% discover, "discovered",
ifelse(data.spr$Item %in% learn, "learned","realized"))))
#   Exclude trials where a chunk is read slower than 6000ms above the average and faster than 100ms
SPR.mean <- mean(data.spr$RT)
SPR.SD <- sd(data.spr$RT)
high.cutoff <- SPR.mean + (2.5*SPR.SD)
low.cutoff <- SPR.mean - (2.5*SPR.SD)
# Absolute RT cutoff
bad.trials <- data.spr %>%
group_by(Experiment, region) %>%
filter(RT < 100 | RT > 6000)
# # 2.5 SDt from mean cutoff
# bad.trials <- data.spr %>%
#   group_by(Item, region) %>%
#   mutate(Cutoff = (mean(RT) + (2.5*sd(RT)))) %>%
#   filter(RT < 100 | RT > Cutoff)
bad.trials$ID <- paste(bad.trials$Subject,bad.trials$Item)
data.comprehension$ID <- paste(data.comprehension$Subject,data.comprehension$Item)
data.spr$ID <- paste(data.spr$Subject,data.spr$Item)
num.bad.trials <- n_distinct(bad.trials$ID)
num.trials.total <- n_distinct(data.spr$ID)
percent.trials.lost <- (num.bad.trials/num.trials.total)*100
data.comprehension <- droplevels((subset(data.comprehension, !(ID %in% bad.trials$ID))))
data.spr <- droplevels((subset(data.spr, !(ID %in% bad.trials$ID))))
# Double check number of subjects
print(data.comprehension %>% summarise(number = n_distinct(Subject)))
print(data.spr %>% summarise(number = n_distinct(Subject)))
View(data.comprehension)
data.comprehension <- left_join(answers,data.comprehension)
data.comprehension$Response <- as.character(data.comprehension$Response)
data.comprehension$Filler <- as.character(data.comprehension$Filler)
data.comprehension$Name <- as.character(data.comprehension$Name)
data.comprehension$Local <- as.character(data.comprehension$Local)
data.comprehension$Answer <- ifelse(data.comprehension$Response == data.comprehension$Filler, "Filler",
ifelse(data.comprehension$Response == data.comprehension$Name, "Name",
ifelse(data.comprehension$Response == data.comprehension$Local, "Local", "Confusion")))
data.comprehension$Filler <- ifelse(data.comprehension$Answer == "Filler", 1, 0)
data.comprehension$Name <- ifelse(data.comprehension$Answer == "Name", 1, 0)
data.comprehension$Local <- ifelse(data.comprehension$Answer == "Local", 1, 0)
data.comprehension$Confusion <- ifelse(data.comprehension$Answer == "Confusion", 1, 0)
comprehension.by.subj <- data.comprehension %>%
group_by(Subject, Islandhood,Dependency) %>%
summarise(av.filler = mean(Filler),
av.name = mean(Name),
av.local = mean(Local),
av.confusion = mean(Confusion))
comprehension.summ <- comprehension.by.subj %>%
group_by(Dependency,Islandhood) %>%
summarise(mean.filler = mean(av.filler),
SEM.filler = sd(av.filler)/sqrt(n_distinct(Subject)),
mean.name = mean(av.name),
SEM.name = sd(av.name)/sqrt(n_distinct(Subject)),
mean.local = mean(av.local),
SEM.local = sd(av.local)/sqrt(n_distinct(Subject)),
mean.confusion = mean(av.confusion),
SEM.confusion = sd(av.confusion)/sqrt(n_distinct(Subject)))
accuracy.subj.by.cond <- data.comprehension %>%
group_by(Subject, Experiment, Dependency,Islandhood) %>%
summarise(average = mean(Accuracy))
accuracy.cond.summ <- accuracy.subj.by.cond %>%
group_by(Experiment,Dependency,Islandhood) %>%
summarise(mean = mean(average),
SEM = sd(average)/sqrt(n_distinct(Subject)),
ci.lower.mean = mean - qt(.975,df=n_distinct(Subject)-1)*SEM,
ci.upper.mean = mean + qt(.975,df=n_distinct(Subject)-1)*SEM)
accuracy.plot <- ggplot(data=accuracy.cond.summ)+
aes(x = Dependency, y = mean, fill = Dependency)+
geom_bar(position = 'dodge',stat = "identity") +
ylim(0,1)+
geom_linerange(stat='identity',position = position_dodge(width = 0.9),mapping=aes(ymax = ci.upper.mean,ymin=ci.lower.mean)) +
ylab("Proportion filler")+
facet_grid(.~Islandhood)+
scale_fill_grey()+
theme_minimal(base_size = 12,base_family = "Charter")+ theme(legend.position="none")
confusion.subj.by.cond <- data.comprehension %>%
group_by(Subject, Experiment, Dependency,Islandhood) %>%
summarise(average = mean(Confusion))
confusion.cond.summ <- confusion.subj.by.cond %>%
group_by(Experiment,Dependency,Islandhood) %>%
summarise(mean = mean(average),
SEM = sd(average)/sqrt(n_distinct(Subject)),
ci.lower.mean = mean - qt(.975,df=n_distinct(Subject)-1)*SEM,
ci.upper.mean = mean + qt(.975,df=n_distinct(Subject)-1)*SEM)
confusion.plot <- ggplot(data=confusion.cond.summ)+
aes(x = Dependency, y = mean, fill = Dependency)+
geom_bar(position = 'dodge',stat = "identity") +
geom_linerange(stat='identity',position = position_dodge(width = 0.9),mapping=aes(ymax = ci.upper.mean,ymin=ci.lower.mean)) +
ylab("Proportion confusion")+
scale_fill_grey()+
facet_grid(.~Islandhood)+
theme_minimal(base_size = 12,base_family = "Charter")+ theme(legend.position="none")
comprehension.plot <- ggarrange(accuracy.plot,confusion.plot,ncol = 2, nrow = 1)
comprehension.plot
QRT.subj.by.cond <- data.comprehension %>%
group_by(Subject, Experiment, Dependency,Islandhood) %>%
summarise(average = mean(RT))
View(QRT.subj.by.cond)
QRT.subj.by.cond <- data.comprehension %>%
group_by(Subject, Accuracy, Experiment, Dependency,Islandhood) %>%
summarise(average = mean(RT))
QRT.cond.summ <- QRT.subj.by.cond %>%
group_by(Accuracy,Experiment,Dependency,Islandhood) %>%
summarise(mean = mean(average),
SEM = sd(average)/sqrt(n_distinct(Subject)),
ci.lower.mean = mean - qt(.975,df=n_distinct(Subject)-1)*SEM,
ci.upper.mean = mean + qt(.975,df=n_distinct(Subject)-1)*SEM)
View(QRT.cond.summ)
QRT.plot <- ggplot(data=QRT.cond.summ)+
aes(x = Dependency, y = mean, fill = Dependency)+
geom_bar(position = 'dodge',stat = "identity") +
geom_linerange(stat='identity',position = position_dodge(width = 0.9),mapping=aes(ymax = ci.upper.mean,ymin=ci.lower.mean)) +
ylab("Proportion confusion")+
scale_fill_grey()+
facet_grid(Accuracy~Islandhood)+
theme_minimal(base_size = 12,base_family = "Charter")+ theme(legend.position="none")
QRT.plot
data.reg <- data.comprehension
data.reg$Islandhood <- ifelse(data.reg$Islandhood == "Non-island", .5, -.5)
data.reg$Dependency <- ifelse(data.reg$Dependency == "RP", .5, -.5)
data.reg$Subject <- as.factor(data.reg$Subject)
Q.rawrt <- lmer(RT ~ Islandhood*Dependency
+ (1|Subject)
+ (0 + Islandhood|Subject)
+ (0 + Dependency|Subject)
+ (0 + Islandhood:Dependency|Subject)
+ (1|Item)
+ (0 + Islandhood|Item)
+ (0 + Dependency|Item)
+ (0 + Islandhood:Dependency|Item),
data=subset(data.reg, Accuracy == 1))
library(lmerTest)
Q.rawrt <- lmer(RT ~ Islandhood*Dependency
+ (1|Subject)
+ (0 + Islandhood|Subject)
+ (0 + Dependency|Subject)
+ (0 + Islandhood:Dependency|Subject)
+ (1|Item)
+ (0 + Islandhood|Item)
+ (0 + Dependency|Item)
+ (0 + Islandhood:Dependency|Item),
data=subset(data.reg, Accuracy == 1))
summary(Q.rawrt)
data.reg$Islandhood <- ifelse(data.reg$Islandhood == "Non-island", .5, -.5)
data.reg$Dependency <- ifelse(data.reg$Dependency == "RP", .5, -.5)
data.reg$Accuracy <- ifelse(data.reg$Accuracy == 1, .5, -.5)
data.reg$Subject <- as.factor(data.reg$Subject)
Q.rawrt <- lmer(RT ~ Islandhood*Dependency*Accuracy
+ (1|Subject)
+ (0 + Islandhood|Subject)
+ (0 + Dependency|Subject)
+ (0 + Accuracy|Subject)
+ (0 + Islandhood:Dependency|Subject)
+ (0 + Islandhood:Accuracy|Subject)
+ (0 + Dependency:Accuracy|Subject)
+ (0 + Islandhood:Dependency:Accuracy|Subject)
+ (1|Item)
+ (0 + Islandhood|Item)
+ (0 + Dependency|Item)
+ (0 + Accuracy|Item)
+ (0 + Islandhood:Dependency|Item)
+ (0 + Islandhood:Accuracy|Item)
+ (0 + Dependency:Accuracy|Item)
+ (0 + Islandhood:Dependency:Accuracy|Item),
data=data.reg)
summary(Q.rawrt)
# Calculate difference scores for the t-tests for effect of RP versus Gap for RT
rt.differences.by.subj.nonisland <- data.spr %>%
group_by(Subject) %>%
filter(Islandhood == "Non-island" & Dependency == "RP" & region == 6) %>%
summarise(RP.mean = mean(RT))
rt.differences.by.subj.nonisland <- data.spr %>%
group_by(Subject) %>%
filter(Islandhood == "Non-island" & Dependency == "Gap" & region == 6) %>%
summarise(gap.mean = mean(RT)) %>%
right_join(rt.differences.by.subj.nonisland)
rt.differences.by.subj.nonisland  <- rt.differences.by.subj.nonisland  %>%
group_by(Subject) %>%
summarise(Difference = RP.mean-gap.mean) %>%
right_join(rt.differences.by.subj.nonisland)
rt.differences.by.subj.island <- data.spr %>%
group_by(Subject) %>%
filter(Islandhood == "Wh-island" & Dependency == "RP" & region == 6) %>%
summarise(RP.mean = mean(RT))
rt.differences.by.subj.island <- data.spr %>%
group_by(Subject) %>%
filter(Islandhood == "Wh-island" & Dependency == "Gap" & region == 6) %>%
summarise(gap.mean = mean(RT)) %>%
right_join(rt.differences.by.subj.island)
rt.differences.by.subj.island  <- rt.differences.by.subj.island  %>%
group_by(Subject) %>%
summarise(Difference = RP.mean-gap.mean) %>%
right_join(rt.differences.by.subj.island)
ttest.nonisland <- t.test(rt.differences.by.subj.nonisland$Difference)
ttest.island <- t.test(rt.differences.by.subj.island$Difference)
ttest.nonisland
ttest.island
